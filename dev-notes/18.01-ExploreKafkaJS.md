## KafkaJS consumer questions

KafkaJS's consumer and how it relates to the adapter needs some thought. KafkaJS's consumer has a `run()` method that executes a message handler or message batch handler.

### Does the `run()` method block?

I'll build a simple test with a single producer and consumer.

-  Move Kafka tests into `test-helpers/kafka` and renaming the files from the last commit to `setupTestConsume.ts` and `setupTestProduce.ts`
-  Change them to `run01*.ts`
   -  Producer runs one producer that will write 5 messages with a 3 second delay
   -  Consumer runs two consumers, one awaiting run, one not, and logs to show where it happens; 1 second delay in the message handler

Output

```
>>>>>>>>>> RUN CONSUMER 2 run not awaited <<<<<<<<<<<<
{"level":"INFO","timestamp":"2022-11-12T13:18:09.223Z","logger":"kafkajs","message":"[Consumer] Starting","groupId":"test-group"}
>>>>>>>>>> AFTER RUN 2 run not awaited <<<<<<<<<<<<
>>>>>>>>>> RUN CONSUMER 1 run awaited <<<<<<<<<<<<
{"level":"INFO","timestamp":"2022-11-12T13:18:09.226Z","logger":"kafkajs","message":"[Consumer] Starting","groupId":"test-group"}
{"level":"INFO","timestamp":"2022-11-12T13:18:30.551Z","logger":"kafkajs","message":"[ConsumerGroup] Consumer has joined the group","groupId":"test-group","memberId":"my-app-3d36e926-b0c2-43f7-96e3-7aca82513678","leaderId":"my-app-3d36e926-b0c2-43f7-96e3-7aca82513678","isLeader":true,"memberAssignment":{"test-topic":[0,1]},"groupProtocol":"RoundRobinAssigner","duration":21327}
{"level":"INFO","timestamp":"2022-11-12T13:18:30.555Z","logger":"kafkajs","message":"[ConsumerGroup] Consumer has joined the group","groupId":"test-group","memberId":"my-app-f9fe7081-3c7b-4ccc-9fe5-34061d24baaa","leaderId":"my-app-3d36e926-b0c2-43f7-96e3-7aca82513678","isLeader":false,"memberAssignment":{"test-topic":[2]},"groupProtocol":"RoundRobinAssigner","duration":21329}
>>>>>>>>>> AFTER RUN 1 run awaited <<<<<<<<<<<<
consume run awaited 2 Message 0 -- 2022-11-12T13:18:36.427Z
consume run not awaited 0 Message 1 -- 2022-11-12T13:18:39.442Z
consume run awaited 2 Message 2 -- 2022-11-12T13:18:42.449Z
consume run awaited 2 Message 3 -- 2022-11-12T13:18:45.457Z
consume run not awaited 1 Message 4 -- 2022-11-12T13:18:48.464Z
```

-  Consumer 2's `consumer.run()` is called and logs INFO that it's starting
-  Post-run message for consumer 2 logged
-  Consumer 1's `consumer.run()` is called and logs INFO that it's starting
-  A consumer joins the group on partitions 0 and 1
-  A consumer joins the group on partition 2
-  Post-run message for consumer 1 logged
-  Message handler output shows the not-awaited consumer is assigned to partitions 0 and 1, the awaited consumer to partition 2

The key point here is that `await consumer.run()` only waits until the group join succeeds or fails.

Which means:

-  The method on the adapter is `subscribe` or similar
   -  Create a consumer, subscribe to a topic, call `run()`
-  The method should `await consumer.run()` so it can handle errors (if any)

### Does the run (or any other method) return an error?

I can use `run01Produce` for this test, but will add `run02Consume`.

-  Run 1 consumer as before, await `run()`
-  Get results for each operation and `console.log()` them

On success, `connect()`, `subscribe()` and `run()` return `undefined`.

Changing `subscribe` to use a topic that isn't created... Doesn't get me anywhere, looks like it's creating the topic. I vaguely remember reading that in the docs.

Looking at the code

-  `subscribe` can throw
   -  `KafkaJSNonRetriableError` if the consumer is running, parameters are bad
   -  Other errors if parts of the subscribe operation fail
-  `run` might return an error if it can't start (join the group and sync), but after it starts, it looks like they'll retry if at all possible
-  Error detection after `run()` starts is mainly from events emitted on the consumer
   -  CONNECT on connection
   -  DISCONNECT on disconnect
   -  STOP when `run()` is stopped by calling `stop()` on the consumer (happens during disconnect)
   -  CRASH when `run()` crashes for some reason

### How do I handle message processing failures?

Based on what I see in docs and code, `eachMessage` automatically commits, so I'll need to use `eachBatch` to handle processing failures.

-  If a processing failure is due to bad message data or format, I want to log the message and remove it
-  If a processing failure is due to dependencies failing (connection), I want to retry the message later

If I'm processing a batch of 5 messages and message 3 fails, can I resolve the other messages and leave only 3?

I'll set up `fail01Produce` to publish 5 messages with a key and `fail01Consume` to fail message 3.

-  Isn't behaving like I want

But I see an option in the docs that uses `eachMessage` and manual commits. Let me try that with `fail02Consume`. ... Nope.

After some more research, I have two basic options:

-  Batch -> If a message in the batch fails, exit the batch processing loop so subsequent messages aren't resolved; next batch read will retry
-  Retry topic -> If a message fails and should be retried, write it to a retry topic; process the retry topic separately
   -  Process the retry topic with a dedicated instance, though that seems like it would have issues for a dependency down
   -  The retrier monitors dependencies and, when they're up, moves messages back to the main topic
-  Possible variation -> retry topic is the main topic, but that might generate a lot of churn
   -  With a retry topic, if I can identify the dependencies it can just wait
   -  OTOH, if the issue is a dependency down, then the main topic can't process anything, so maybe just feed it back to the main topic

Let's try the "main queue as retry queue" theory with `fail03Consume`. It works, but it blocks, which is probably reasonable if we only stage retries for dependency (connect) failures. DER behaves similarly, so this seems acceptable.

After 5 retries (configured on the client -- `const kafka = new Kafka(...)`), the consumer fails, stops, disconnects, and restarts, picking up where it left off.

One issue I see is that, on restart, it reads the message before the failed message. I may be committing wrong. Also, I'm reproducing the message, but it has the same offset. Commenting the reproduce part of the message handler the consumer reads the topic until it's empty and goes quiet (waiting). Restarting sits idle.

I think when I commit offsets, I need to commit the message offset + 1 because the offset determines where to start, not what's done.

If I use a retry topic, messages continue processing. But if the only errors that lead to "don't commit offset" are dependency connect errors, later messages will fail too and end up in the retry topic until the dependencies are available. The retry topic is like `DelayedEventRunner`. So, I think it's reasonable to reproduce to the main topic for retriable errors.

## Mapping concepts

-  Kafka and the client is something like `DomainEventBus`
-  Events wait on the aggregate until time to publish them
-  I need a `publishForAggregate` that takes an `AggregateRoot` and calls the adapter `publish` for each event
-  The adapter `publish` effectively replaces `DEB.publishToSubscribers()`
-  The consumer `run()` is something like a subscriber (`BackupRequestCreatedSubscriber`, etc.)
-  The message handler method is something like the `on...` method on the existing subscribers
-  The adapter `subscribe` sets up the consumer and calls `run()` on it, using a method something like `fail03Consume`
-  In the `run()` message handler, for each message, call the passed method handler
-  If the result of the passed message handler should be retried, reproduce the event
   -  The key is ensuring message handlers return a consistent retryable indicator
   -  I'd like to have a way to be aware of dependency state so I can fail fast if I believe the dependency is down so the message handler can fast-fail
   -  I'd like to ensure the Kafka read delays can run fairly long for dependency down (minutes)
      -  In KafkaJS, I can [configure retries on the client](https://kafka.js.org/docs/configuration#default-retry)
      -  I may want different clients for the consumer and the reproducer so they can have different retry behavior
      -  This may be a case for `pause()` (https://kafka.js.org/docs/1.11.0/consuming#a-name-pause-resume-a-pause-resume) and pause the topic while the dependency is down -- need to be sure long pauses don't lead to session timeouts

This leads me to believe I'll still have something like `DomainEventBus`, but for Kafka with certain functions removed and certain functions changed to use the adapter. I wonder if I can change the existing DEB and make it and the Kafka DEB have the same interface.

## What's next

-  Define an event structure and one or two events
   -  Events have getters for `messageKey()`, `messageData()` and `topicName()`
-  Build the Kafka adapter
-  Change the enqueue request use case to publish an event
   -  For now, create the event in the use case so I don't need to change `AggregateRoot`, etc.
-  Build a message handler for the event and have it run a modified create use case
-  Decide if I'll build something like `DomainEventBus`
   -  Needs an adapter for Kafka
   -  `publishEventsForAggregate` -- iterates events on an `AggregateRoot` and calls adapter `publish`
      -  I don't have anything that would generate more than one event type or any event type with >1 subscriber, so may defer
      -  But if I can make existing DEB and new DEB-like use the same interface, I might build this for compatibility
      -  Or maybe it's time to declutter -- remove prisma, fastify, legacy DEB, etc.; or pull them into secondary directories
   -  Method to register a handler for a consumer group and topic, takes a handler method and subscribes it
      -  Is this really more than the adapter `subscribe`

**COMMIT: DOCS: research KafkaJS and notes on what I see and how it affects plans**
