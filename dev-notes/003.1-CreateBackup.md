# Create request

## Plan

-  [3.1.1](3.1.1-UseCase.md) - Get the request backup use case working (use case, domain entity)
   -  Include unit tests for everything
   -  The use case needs a repository, so write a stub repository to always return ok for now
-  3.1.2 - Get the backup request controller and mapper working
   -  Mapper unit tests confirm it maps data to/from as expected
   -  Controller unit tests run the use case
-  3.1.3 - Create the router and add a route, call it with Insomnia and get a result
   -  Requires wiring into express api
-  3.1.4 - Pick a database of some kind and write the repository to connect to it
   -  Unit tests mock the database interface
-  3.1.5 - Build use case to check if allowed
   -  Make get backup job data a stub for now
-  3.1.6 - Build use case to send to BZI
   -  Make a send to queue a stub for now, will add queue connection later
-  3.1.7 - Build event handler and add event emits in use cases

### Use case design

-  Actor: Backup data package creator (generates backup data set)
-  Use case: Request backup (command)
-  Domain: Backup control -- store
-  Records an backup request in the request log

I want separate use cases to confirm the request is valid and send to the backup zone interface because different inbound transports will need to execute different use cases.

-  For data from HTTP, confirm the request is allowed before responding so we can return a failure if the request isn't allowed.
-  For queue, do not confirm first--acknowledge the message when the request is stored.

So, make them separate use cases and controllers for different transports may call different use cases. I think I want to generate events to trigger confirmation for queues and send for HTTP so the controllers can finish while backup control continues to process the parts of the request they don't care about. Node has an `EventEmitter` class that should meet the need. See also [this article](https://www.digitalocean.com/community/tutorials/using-event-emitters-in-node-js) from Digital Ocean for an example (fairly sophisticated too). I looked at some other eventing packages, but I think the native `EventEmitter` is adequate.

The separate cases affect restarts.

-  HTTP requests that are not confirmed should be ignored. The caller got a timeout and should retry.
-  Queue requests that aren't confirmed need to be confirmed.

I don't like how that rule pushes transport level knowledge into the application, so maybe the create use case accepts a parameter that tells it if it should store the data in the repository or not. If the controller needs to execute another use case to complete the request, it can pass the created request DTO to that use case and let it create the request. Or the controller could pass a parameter that sets a flag to indicate if the request should be processed on restart. The HTTP controller can let the confirm use case set the flag (probably confirm should always set the flag). Then restart only picks up unsent requests that should be processed on restart and resumes them.

After some more thought, I think I'll push this into the database.

-  Put a "get on start flag" on the request log, which tells me if the request should be picked up and handled during restart.
-  The controller passes an initial value for the flag (0 for HTTP, 1 for queue).
-  The create request use case stores the value as part of the backup request entity and triggers the confirm event as it returns to the controller.
-  The confirm use case sets the flag to 1 if confirmed or 0 if not allowed.
-  The send use case sets to flag to 0 when sent to the backup zone interface.
-  On start run the start is a use case for rows where flag is 1. Based on the status, trigger the next event.

### Request DTO

-  api version -- yyyy-mm-dd string -- allows us to deal with API changes without changing request URLs
   -  Should the controller deal with API version recognition and acceptance? Or does that belong in the use case?
   -  I'm inclined to put it in the controller, but that may put too much business knowledge in the controller.
-  backup job id -- UUID string -- identifies the backup job under which the request is being made
   -  Use this to confirm the request is valid
-  data as of date -- Date (time 00:00:00) -- the date of the data in the backup (affects when it can be deleted)
-  prepared data location -- string -- where the AZI should get the data to store in the backup zone
   -  May be a URL, path, etc., depending on the platform the AZI supports
-  requester id -- string -- identifies the account id submitting the backup request
   -  HTTP controller needs to figure this out based on OAuth token.
   -  Queue controller needs to get this from the message, so whatever enqueues the message needs to get the caller's id.
-  request id -- UUID string -- identifies the request for distributed tracing
   -  Queues disconnect the requester from BC, so putting data on the queue needs to generate a request id to return to the requester for tracing. Queue controller will pass the request id from the queue message.
   -  HTTP controller will not rely on the requester for a request id. HTTP controller generates request id and includes in DTO to the use case.
-  received timestamp -- Date -- when the controller received the request
   -  May not want in the request log, may store in an application log.
-  save flag -- boolean -- true if the use case should write the request to the request log
   -  Set by the controller based on the transport the controller supports.
   -  If false, the controller should call a use case that will write to the request log.

### Request Log

-  request id (UUID from DTO)
-  request status name -- received, allowed, not allowed, sent, completed, failed
-  received timestamp -- include as part of PK to guard against duplicate UUIDs ?????
-  allow check timestamp -- allowed or not allowed
-  send timestamp
-  reply timestamp -- completed or failed (completed includes store in backup list)
-  backup job id
-  data as of date
-  prepared data path
-  get on start flag -- should the request be processed when the service starts
-  requester id -- may be useful for security tracing
-  request transport name -- (HTTP, CloudA Queue, CloudB Queue, etc.) -- might be interesting to understand traffic

Ideally, some of this data belongs in an application log, not the request log, but I'm delaying application logging for a bit. (Some quick research suggests Bunyan is a good logging tool. Eventually maybe add Logstash and ELK to get a Splunk-alike playground.)

### More restart thoughts

If we have more than one instance of the service running, on restart we need to ensure only one instance attempts to process restarts.

The "confirm" restart branch would read unconfirmed and call the confirm use case. If confirm was successful, emit an event to trigger the send use case.

The "send" restart branch would emit events to trigger the send use case.

### Major steps for use case

-  create domain value objects for data in the DTO -- verify they create (no errors)
   -  I'm thinking I may want a value object class after all, but TBD how far I go
-  request status = received
-  confirmed, sent, completed timestamps => null
-  maybe check request doesn't already exist (request id) -- error if it does ?????
   -  How much am I willing to trust UUID to be unique enough?
   -  Or will repo return an error
-  if save flag, write to repository
-  return result

### Supporters I'll need

-  Backup request entity with the attributes, private constructor, create -- will need more later, but that's all for now
-  Backup request repository with exists, save -- will need more later, but that's all for now
-  Backup request mapper toDTO (from domain), toDomain (from persistence), toPersistence (from domain)
   -  Stemmler's create use case maps DTO to domain because each use case has its own DTO to deal with use case specific data needs
   -  But I wonder if update will need the same mapping and that will justify a mapper for it
   -  In linebacker's case, updates to the backup request after create will only need a request id, status, and timestamp from the DTO -- make a single update status use case that sets the right timestamp based on the status (get request by id, change status and timestamp, save (overwrite))
   -  I prefer to be explicit -- domainToDTO, domainToRepo, repoToDomain
-  AND TEST EVERYTHING!!!!

## Other

Installed `prettier` and ran it on `src` contents, so all files changed for formatting.

**COMMIT: 3.1.0 - plan create backup feature**
