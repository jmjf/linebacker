## Queue adapters

I need to build adapters that can talk to the queues linebacker will use to send create messages to the backup interface and receive status messages from the backup interface.

## Planning

The "send" adapter should take a backup request, build a message to send to the queue, and send the message.

-  Currently, the interface returns a boolean; need to handle errors or similar situations, so will probably promote it to a `Result`
-  I'm using Azure Storage queues as my first target
-  For initial "get it working," I'll connect to a local Azurite queue
-  For unit testing, I'll figure out how to mock the connection
-  I want some code that the adapter uses that will
   -  Manage connections to the queue
   -  If the queue is unavailable, act as a sort of circuit breaker
   -  Keep a list of messages awaiting send (if circuit breaker is open/connection not possible)
   -  Send waiting messages when the circuit breaker closes/connection established
   -  Point being: don't put the reliability complexity in the adapter if possible

The "receive" adapter is a controller (receives a message, does basic checks, calls the receive use case).

-  As above, I want to put the Azure connection and polling in code that calls the queue controller/adapter--sort of "Fastify/Express-alike for Azure Storage queues"
-  The controller is a message handler that gets hooked up to the framework for queues

I'll focus on the "send" adapter and Azure code behind that first, then come back and plan the "receive" adapter

-  Use the Azure SDK to build the lower level send process
-  The goal is a method the adapter can call to send a message and get a status back
   -  That method should manage connection, circuit breaker behaviors, etc.
-  Use that to get the adapter working (Azurite)
-  Write unit tests that mock the lower level method
-  Work on circuit breaker and holding pending messages
-  I want to initialize the connection on server startup, I think
   -  Cache credentials in the lower level code
-  Look at some of the Azure queue packages people have built on npm
   -  Some are old, but they're a source of ideas
   -  `azure-abstract-queue-adapter`, `azure-storage-simple`, `tsdatautils-azurestoragequeue` (ideas)
   -  I think I already have much of this in code I hacked together figuring out Azure Storage queues, but could be better organized

What information does the lower level code need?

-  Credentials to connect (may need to be able to refresh while running)
-  Storage account information
-  Queue name
-  I want to be able to use different queues, so need a way to identify the queue
   -  Queue identifier is storage account + queue name, so define a logical identifier the adapter can use and the low level code can look up
   -  Register all queues on startup

Before starting, rename adapters and get all tests passing again.

**COMMIT: REFACTOR: rename adapters and get tests passing**

## The real plan

What does the adapter need to do?

-  Send a message to the queue
   -  On ok, return something meaningful about the message so we can log it
   -  On err, return an `AdapterError` so we can handle it
-  Also on ok, notify CB so it can manage counters and state
-  Also on err, if err is a low-level issue, add the message to the circuit breaker
   -  Make circuit breaker reusable
   -  It should cache messages that are backed up
   -  Decide how to handle the resend on okay--preferably with an event

Get the basic adapter together first, then write the CB code with an eye toward reusability. We'll need it for the BackupJobService

### Azure Queue parts

To connect to an Azure Queue, I need a credential

-  `DefaultAzureCredential` -- to connect to a queue on Azure, use environment variables with the secrets
   -  `AZURE_TENANT_ID` -- AD tenant id
   -  `AZURE_CLIENT_ID` -- application id of App Registration (in the tenant)
   -  `AZURE_CLIENT_SECRET` OR `AZURE_CLIENT_CERTIFICATE_ID` -- client secret for the App Registration OR path to PEM
   -  NOTE: requires these env names because it pulls from env directly.
   -  [DefaultAzureCredential](https://docs.microsoft.com/en-us/javascript/api/@azure/identity/defaultazurecredential?view=azure-node-latest)
   -  [EnvironmentCredential](https://docs.microsoft.com/en-us/javascript/api/@azure/identity/environmentcredential?view=azure-node-latest)
   -  We may be able to go directly to an `EnvironmentCredential`
   -  Documentation says `ManagedIdentityCredential` only works for on-Azure resources
      -  Alternate option is HTTP an Azure Function with a function key so we don't require Azure credentials off-Azure
      -  Then Function can use a managed identity to talk to the queue and control message format
      -  If the function key changed, we'd need to update it in the application (environment)
-  `StorageSharedKeyCredential` -- this works with Azure, but the main use case is Azurite for local dev/test
   -  `ACCOUNT_NAME` -- storage account name
   -  `ACCOUNT_KEY` -- storage account key
   -  NOTE: recommended env names; must pass values to the constructor, so options on where to get the data
   -  In a production on-Azure environment, you don't want to give out storage account keys; also have to update them when you rotate them
   -  In Azurite, this is the only way to connect
-  Build connection solution to take an option that tells it what type to use and return the appropriate type

To communicate with the queue, I need a `QueueClient`, which requires

-  Queue URI -- storageAccountName/queueName
-  Credential -- from above
-  Options -- [StoragePipelineOptions](https://docs.microsoft.com/en-us/javascript/api/@azure/storage-queue/storagepipelineoptions?view=azure-node-latest), which is composed of several other options objects, so click into them for details
   -  Most interesting options are probably `proxyOptions` and `retryOptions`
   -  [ProxyOptions = ProxySettings](https://github.com/Azure/azure-sdk-for-js/blob/f9a971a5a5dc130348671a9cde16cbe486dcee48/sdk/core/core-http/src/serviceClient.ts#L68)
   -  [StorageRetryOptions](https://docs.microsoft.com/en-us/javascript/api/@azure/storage-queue/storageretryoptions?view=azure-node-latest)
-  [QueueClient](https://docs.microsoft.com/en-us/javascript/api/@azure/storage-queue/queueclient?view=azure-node-latest#@azure-storage-queue-queueclient-constructor-1)

Given a `QueueClient`, interesting methods include

-  `createIfNotExists` -- ensures the queue exist; in the real world, we'd expect the queue to be provisioned by CI/CD
-  `sendMessage` -- publish a message to the queue
-  `receiveMessages` -- read a message from the queue; if the message isn't deleted within a timeout, it reappears on the queue
-  `deleteMessage` -- delete a message from the queue; after any processing is done

### What I want to have

For now, I'm planning to use credentials.

-  A function that returns a credential (`DefaultAzureCredential | StorageSharedKeyCredential`)

   -  Options tell it which to get and may pass values for the `SSKC`
   -  I could accept options for the `DAC` and set them in `process.env` maybe
   -  This returns a new credential object every time so everything using a credential gets its own
   -  Also works fine for anything that wants to fail, get a fresh credential and try again before really failing
   -  Avoids a lot of complexity with timeouts and automatic refreshes; let everything handle it's own

-  `QueueSender`

   -  Supports sending messages only
   -  Constructor takes an `AzureCredential`, among other things
      -  `getCredential`, assemble the queue URI and any options, create a `QueueClient` instance
   -  If a send fails, try to `getCredential`, recreate the `QueueClient` and send again
      -  If second send fails, it's a real fail
      -  I imagine there are several small, focused methods so `send()` can call them to do what it needs to do

-  `QueueReceiver`
   -  Supports receiving messages only
   -  Constructor is similar to the sender
   -  The receiver runs a loop that reads the queue and, if a message is found, runs the use case for it
      -  If the use case succeeds, delete the message
      -  If the use case fails due to bad data, log and delete the message
      -  If the use case fails due to some other reason, do not delete the message (it will reappear later)
      -  While messages, loop quickly, but if no messages, increment a delay so we poll less frequently

Another option--if the process writing the queue for a receiver uses an Azure Function, the Function could write the queue and call an HTTP endpoint to trigger reading and processing a message, which would avoid a polling situation. Or we could use an Event Hub to fire an HTTP call to trigger the reader.

[Storage Queue reference](https://docs.microsoft.com/en-us/javascript/api/overview/azure/storage-queue-readme?view=azure-node-latest)

[Source code on GitHub](https://github.com/Azure/azure-sdk-for-js/tree/main/sdk/storage/storage-queue)

### More research and thinking

Constructing a `QueueClient` doesn't actually connect, it only sets up the context to connect. In the SDK source, there are no `await`s outside calls that perform operations on the queue. The main reason to make the sender and receiver objects is so I can persist the queue client, but maybe constructing it isn't costly and I could do that every time I call send. In that case, I could make send and receive functions that create their `QueueClient` every time.

Alternatively, I could make a single `AzureQueue` that does everything. The constructor sets up the credential and `QueueClient`. The send, receive, and delete message functions take care of all the formatting, response restructuring (`Result`), etc., for those operations. I don't worry about the concept that adapters are one-way and only need one function.

The polling loop goes in a controller, not an outbound adapter. It can use the receive and delete functions in its polling loop. If I change to an Azure Function writing the receive queue and calling HTTP to trigger a read, I just rewrite the controller. I may write a base poller controller that serves as the basis for specific controllers.

Let's think about how I'll use this, starting with the sender.

The `SendToInterfaceUseCase` will have a "send to queue" adapter for its queue. It wants to let that adapter handle all the mechanics of retry, holding onto failures and retrying them when the circuit breaker closes, etc.

The adapter's main functions are:

-  Try to send the message to the queue
-  If the send fails, store something that will let it retry the message later
   -  The retry could be handled entirely in the adapter
      -  Implies it stores the whole message ready to go and the backup request id so it can log it when it succeeds
      -  Problem: We don't want the request statused Sent before it's actually sent; this approach means the adapter has to do something to status it Sent
   -  The adapter could set up events to run the use case again
      -  It needs and event to dispatch; I'd like to avoid storing a whole `BackupRequest`
   -  So, what if I
      -  Define an event, `BackupRequestRetrySend`
      -  The event's constructor takes `backupRequestIdentifier` instead of the whole `BackupRequest`
      -  The event's `getAggregateId()` creates a `UniqueIdentifier` from the id
      -  Store the event in an array in the adapter
      -  When the circuit breaker closes, read events from the array
      -  Call `DomainEventBus.publishToSubscribers()` with each event
      -  Delete the event from the array
   -  Considerations
      -  Requires making `publishToSubscribers()` public, but I think I can live with that
      -  Probably should store request id + event so I can avoid two events for the same request (how likely is that)
      -  If I separate the circuit breaker so it's reusable, I can give it a factory function that returns an event of the right type
         -  I'll have sends for backup, delete, and restore requests, so need separate adapters for each, all of which need this capability
         -  In this case, I could store just the id; maybe even without it, because adapter could know the event it needs to create and do that as part of the loop that reads the array.
         -  In the id only case, I could use Set to guarantee uniqueness. Use `for...of` to iterate the set)
      -  Maybe adapter has a circuit breaker to manage retries
         -  Can check CB to see if it's okay to send or just give it to the CB
         -  CB is responsible for testing connection (an exists function parallel to the send function; or maybe create if not exists)
            -  If `QC.exists()` gets an HTTP error other than 404 (doesn't exist), it looks like it throws [ref](https://github.com/Azure/azure-sdk-for-js/blob/f9a971a5a5dc130348671a9cde16cbe486dcee48/sdk/storage/storage-queue/src/QueueClient.ts#L777)
-  Return a `Result` to the use case so it can status Sent or not and log appropriately.

If the adapter can call a send function that deals with the queue message wrapping, it should be good

-  Get credentials
   -  Assume we set up env because that's the smart move for security
-  Create a queue client
   -  Needs a queue name, but assume we put all the send queues in one storage account so can get from env
   -  Options should default always
-  Set up the message
   -  Ensure the queue exists
   -  Base64 the message
   -  Call `queueClient.sendMessage()`
      -  If it fails, no need to retry right away because we just got credentials and connected the client so it's a real failure.
   -  Return the `Result`
   -  Put that function in `common/infrastructure/AzureQueue.ts`, which can include helper functions so send isn't giant
      -  May be exported functions for key operations
      -  Could be a static object

Okay. I'm liking this plan. This sounds like a good balance between keeping common code (message wrapping, queue connecting, etc.) shareable without getting overly complex. The circuit breaker bit seems doable with compact data storage--still some details to work out, but this is a good foundation.

Later, thinking about the circuit breaker, what if

-  Constructor took a method to call to send data (or request data)--pass a method on the adapter
   -  Anything sent to it needs to be flexibly structured because the CB won't know the type
   -  Should do zero data formatting; gets whatever it needs, maybe in an opts object
-  Constructor took a factory method to get an event object to retry--pass a method on the adapter
-  Provided a method that executes the send/request function, sets up the retry if it fails, and returns the result of the method

Then the circuit breaker can control calling the action and fail fast if open. Code is reusable across a range of cases.

8.1 - Send function

-  Figure out how to make this testable; how close can we get to the Azure SDK without adding a ton of mocks
   -  `jest.mock()` the library in the test and mock the function you care about in the test; `jest.ResetAllMocks()` after each test
   -  Only overridden functions are affected

8.2 - Backup Request queue adapter

-  Uses send function that is passed to it (constructor) maybe
-  Understand how send affects testability

-  `mapToQueue(backupRequest)` assembles data for the queue
-  `sendMessage(backupRequest)` calls `mapToQueue` to get a raw object for the queue, then calls the low level queue code

Look at the Azure Queue code you have and get a sense of what will be happening there.

A couple of reference links
https://docs.microsoft.com/en-us/javascript/api/@azure/storage-queue/queuesendmessageresponse?view=azure-node-latest
https://docs.microsoft.com/en-us/javascript/api/@azure/storage-queue/messagesenqueueheaders?view=azure-node-latest

8.3 - Plan receiver

**Rest of this will change**

8.4 - Queue receiver

-  Need to decide how I start a poller running
-  Separate initialize, start, stop methods
   -  Initialize needs to register handler
   -  Start needs to be async, but not awaited so it runs in the background
   -  May want to run in a separate worker (but node docs say they're aimed at CPU not I/O, this should be mostly I/O)

8.5 - Receive controller

-  Gets a message DTO and runs the receive use case
-  Should be able to unit test it directly
-  May be more like a handler method that gets passed to a receiver and left to run

8.6 - Can I keep low level code out of linebacker

-  Easy way is to build in a separate repo, maybe link repo to linebacker
-  Or monorepo??
-  Need to do some research
