# More SplunkLogging improvements

## Log queue problem

Note: POST = post logs to Splunk

The log queue (an array) accumulates logs until `SplunkLogger` POSTs them.

`SplunkLogger` POSTs logs based on

-  timeout -- every x milliseconds
-  item size -- accumulated bytes of stringified items in the array
-  item count -- queue.length

If POST fails, `SplunkLogger` adds a failure log item to the queue and resets the queue size accumulator to 0 to avoid an immediate retry. It does not clear the queue, preserving log entries until they can be sent. There's a limit of 5 such entries at a time to avoid posting thousands of POST failure log entries.

If the Splunk instance is down for a long time, the log queue could get large. If that happens, trying to POST the whole queue as a single batch could overwhelm Splunk with a huge batch of logs in a single POST or the resulting POST body could be too large. The HEC has a limit on the maximum message size; [Splunk documentation)](https://docs.splunk.com/Documentation/Splunk/9.0.1/Admin/Limitsconf#.5Bhttp_input.5D) says the limit is 800MB by default.

I want to avoid overwhelming Splunk or blowing up a web server with a huge POST body.

## Plan

Define a value, `_maxPostItems`, which will be either a value from options or `_maxBatchItems` (if > 1) or 200. I'm choosing 200 as a default because:

-  Consideration 1
   -  Assume the average log is ~4KB
   -  Assume the HEC limit may not be small enough to avoid overwhelming the instance with a large batch
   -  Then
      -  For short outages, 100 will likely empty the queue in a single POST
      -  For long outages, 100 will empty the queue quickly while avoiding risks of batch or HEC limits
-  Consideration 2
   -  I don't see anything in the documentation stating how many log entries Splunk can handle in a single POST
   -  But let's assume there's a practical limit
   -  Then 200 is likely reasonable

In `flushQueue()`, batch logs in `_maxPostItems` chunks. If `queue.length > _maxPostItems`, delay `_postRetryDelayMs` before POSTing the next batch. Also, `flushQueue()` will need to know if it's running to avoid competing with itself.

Some of these concepts are similar to `DelayedEventRunner` and how it manages the loop that publishes events.

-  [x] Fix alternate configuration items handling
   -  If `_maxBatchBytes`, `_maxBatchItems`, or `_maxBatchWaitMs` aren't configured, `addEvent()` will always `flushQueue()`
   -  But what if I simply want to post based on a subset of those items; I want the unconfigured item to be ignored
   -  So, in configuration, default to -1 if any is configured or a safe value
   -  And where these values are used, be sure they aren't -1
-  [x] Add configuration values and initialize
   -  Decided to make post retry = http timeout because naming would be confusing, so no separate value for that
-  [x] `flushQueue() changes`
   -  [x] Add `_queueFlushing` and default to false; set when starting `flushQueue()`
   -  [x] `slice()` logs to post from the queue and `join()` them
   -  [x] post logs
   -  [x] If post succeeds, `splice()` entries off the queue
   -  [x] If queue empty, zero `_httpErrorCount`
   -  [x] If `_httpErrorCount` > 0, delay `_postRetryDelayMs`
   -  [x] Loop until the queue is empty; don't check error count to avoid blocking post when reaching max error count
   -  [x] Use `postErrored` to identify when the post errors (set true in catch) and stop loop

I was trying to manage the `postErrored` concept with `_httpErrorCount`, but that was getting hairy. So I added `postErrored` because it is clearer, simpler, and more reliable.

I tested to see log events flowed with HEC on. Posted once, saw it log, then turned HEC off and posted 100 times to the application. Each post to the application generates ~5 logs.

After three consecutive POST error messages on the console (original POST or retry POSTs failing), and no changes to Splunk logs, I turned HEC on again. Next query saw the errors and the last few posts in the log. In a 15 minute period, I had 103 different backupRequestId values, which was consistent with my testing.

So, this seems to work.

**COMMIT: REFACTOR: change log flushing to limit POST size when recovering from Splunk connectivity failure**

## Queue length can cause immediate retry after POST errors

-  [] Separate input queue and flushing queue.
-  [] On flush, copy input to flushing and empty input.
-  [] Use flushing queue to POST.
-  [] Append POST errors to flushing queue.
