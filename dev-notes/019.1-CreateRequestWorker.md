# Build a worker to create a request

## What needs to happen?

Starting point: `AcceptRequest` received an HTTP request and put it on the `Accepted` queue.

Now I need to:

-  Get the request off the `Accepted` queue (`Worker`)
-  Call a `ReceiveRequest` use case
-  If the use case succeeds, mark the job done else ensure it retries
   -  Consider perma-fail job vs. connect errors causing it to fail

`ReceiveRequest` needs to:

-  Try to get the request from the database (by id)
-  If the request exists (ok) and is not in Received status, error
-  If the request exists (ok) and is in Received status, set the request to the db result
-  If the request does not exist (isErr())
   -  Create the request from the data
   -  If create fails, error
   -  Save the request
   -  If save fails, error
-  Publish request to `Received` queue
-  If publish fails, error

## Tests

For `ReceiveRequest`

-  when the database read fails, it returns a `DatabaseError`
-  when the request exists and is not in Received status, it returns an `InvalidStatusError`
-  when the request does not exist and the data is bad, it returns a `PropsError`
   -  This case will rarely happen because `AcceptRequest` creates the request to ensure data is valid before putting it on the `Accepted` queue
-  when the request does not exist and the save fails, it returns a `DatabaseError`
-  when the request does not exists and publish fails, it returns a `QueueError` (or similar, TBD)
-  when the request exists and is Received and no failures, it returns ok and publishes to the queue but does not save the request
-  when the request does not exist and no failures, it returns ok and publishes to the queue and saves the request

For the `ReceiveWorker`

-  when the use case succeeds, it marks the job complete
-  when the use case fails due to a connection error, it requeues the job
-  when the use case fails and the request has failed > MAX_RETRIES times (ignoring connection errors), it marks the job failed

## How does the BullMQ Worker work?

-  Conceptually, it's similar to the current `Subscriber`
-  `new Worker(queueName, async (job: Job) => {}, opts?)`
-  The function in the signature is the message handler, like `Subscriber`'s `on*` methods
-  If the use case fails, the message handler will need to `throw`
   -  If the error is unrecoverable, `throw new UnrecoverableError('message')` and the job won't retry
   -  If the job should be retried, throw something else
   -  If the handler returns, the job is considered successfully completed
-  Handler is responsible for logging
-  For retries, I'll need a custom backoff function
   -  `opts` -> `{ backoffStrategy: (attemptsMade: number) => number }` where the result is how long to delay before next retry
   -  Set max retries to a very large number and rely on logic in the handler to kill jobs that have retried too many times
-  If a job will be retried, use `Job.update()` to update the job data
   -  On a connection error, increment connection error count
   -  `Job.attemptsMade` is total retries
   -  If `Job.attemptsMade - Job.data.connectionErrorCount > TBD` perma-fail the job

This means the job's data has a connect failure count plus the data. I may want to define a base definition to extend:

```typescript
export interface IEvent {
	eventData: unknown;
	connectFailureCount: number;
}
```

I'm not sure how I'll test the `Worker`.

-  `Worker.processJob(job: Job, token: string)` -- I may be able to build a job and process it
-  Maybe better, build the handler function separately and pass it as a parameter to the worker
   -  `async function handler(job: Job) { ... }`
   -  `worker = new Worker('queue', handler, opts)`
   -  Then I can test the handler without worrying about the `Worker`
   -  This approach doesn't test retry, etc., but I'm not sure how to approach retry testing in jest, so maybe that's better left for integration testing

**COMMIT: DOCS: plan a worker to read accepted and make it received**

NEXT

-  Write the worker tests and worker - use a simple function as a stand-in for the use case `execute()`
   -  Goal is to see if I can use `processJob`
-  Think about how to organize
   -  Should the queue adapter own all the queues and look them up?
      -  Might enable pausing, etc., if queue operations fail due to connect errors
   -  Should I have a generic worker that takes a handler?
