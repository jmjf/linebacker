# Add CreateBackupRequestController

## Plan

-  Rename `create-request` and `CreateRequest*.ts` to `create-backup-request` and `CreateBackupRequest*.ts`
-  Can I write tests for the controller? Can they replace the tests for the use cases?
   -  If can write tests, do so. Adjust tests as needed.
-  Write the controller
-  Replace controller in `zz-learn-fastify`

## Rename "create request" to "create backup request"

**Purpose:** Rename all "create request" to "create backup request"

**Why:** I'll need a way to track "create backup," "delete backup," and "restore backup" requests and their progress through the system. Name everything to be explicit about the type of request involved.

[x] Rename `create-request` to `create-backup-request`
[x] Rename `CreateRequest*.ts` to `CreateBackupRequest*.ts`
[x] Remove `apiVersion` from the DTO--the controller will map api versions to the DTO
[x] Ensure all references still work (walk through files)
[x] Ensure all tests run

**COMMIT: 4.2.1 - REFACTOR: create request -> create backup request**

## Write tests for the controller ???

I think I can. Those tests might be able to replace the unit tests for the use cases, but I think I'll keep the use case tests for now because controllers are more closely related to concerns outside of the bounded context (application + domain layer).

Considerations:

-  Stemmler's controllers aren't testable because they return directly to the caller.
-  Bazaglia seems to follow a similar pattern.

But I want to have automated tests in place for the API returns, so I'm going to figure out how to do it.

-  Testing requires putting data in a `FastifyRequest` and reading data off of a `FastifyReply` to validate.
-  I think I can have the controller return a response that the route can then `reply.send()` to close out the request.
-  Then the test can inspect values on the `FastifyReply` and the returned value.
-  At least, I think that will work. I'm going to find out.

### Can I set up the reply in the controller and return the data to send to the route?

[x] Change hello world controller to set up the reply and return data
[x] Change hello world route to get the result, log it, and `reply.send()` it
[x] Test with `curl`

-  Seems to be basically working, but...returns `{value: { ... }}` and log isn't handling objects well
   [x] Change controller to return `result.value` or `result.error`
   [x] Change logging in route

This works, so let's go with that strategy.

**COMMIT: 4.2.2 - TEST: controller sets up but route actually responds (enables testing controllers)**

### Tests

-  when `apiVersion` is not a known apiVersion, it returns 400 and an error
   -  expect `reply.statusCode` 400
   -  expect `result.error.message` toMatch `apiVersion` and `missing or invalid`
-  when the use case has an unexpected failure, it returns 500 and an error
   -  expect `reply.stausCode` 500
   -  expect `result.error.message` to exist
-  when the request is good, it returns 200 and response data
   -  expect `reply.statusCode` 200
   -  expect `result.value.requestId` to be a UUID
   -  expect `result.value.statusTypeCode` to be `Received`
   -  expect `result.value.receivedTimestamp` to be between `startTimestamp` and now

### What to do

[x] Write `FastifyController` class (base class all `fastify` controllers derive from)

-  Include what you know you need right now, add to it later
   [x] Write shell `CreateBackupRequestFastifyController` that does nothing
-  Tests will need it, but it does nothing so they'll fail
-  `...FastifyController` because I could have other controllers for different frameworks, queues, etc.
   [x] Write test for invalid `apiVersion`

**Problem:** I need a `FastifyReply` with enough functionality to meet the controller's requirements. But `fastify` doesn't provide a way to get one easily (that I can find). Instead, I need to use [`fastify.inject()](https://www.fastify.io/docs/latest/Guides/Testing/). So, that forces testing controllers in a more integration/end-to-end mode. I'll need routes and an api module that sets up the application api.

[] Read about `fastify.inject()` testing

-  How can I test routes with fake repo, etc. (test vs. acutally running the api)?

### Fastify testing notes

-  Separate the code that starts the server (`server.js` in the docs) from code that creates the `fastify` instance (`app.js` in the docs).
   -  Looking at `zz-learn-fastify/index.js` that's means passing options to a function that calls `fastify()`, adds routes, and all the other stuff that is the core of the application and returning the `FastifyInstance` that produces.
   -  Logging is an option passed, so you can turn it off (or on) in testing.
   -  The server part builds the app with run time options and starts listening.
-  In the test, import the `FastifyInstance` creator and get the instance. Let's call this `fi`.
   -  Call `response = fi.inject({method, url, etc.})` to simulate an HTTP call. (can also use method chaining.)
   -  Expect results in the response (status code, body contents, etc.)
-  You can use the same `FastifyInstance` for many tests (save rebuilding it).
   -  When done call `fi.close()`

How do Stemmler and Bazagila handle routes?

-  Stemmler has `infra/http/routes/index.ts` in each module.
   -  Creates an `express.Router` (exported) and adds routes to it, calling controller `execute` methods.
   -  In `shared/infra/http/api/v1.ts`, import all the routes and add their routers to a new `express.Router`
   -  In same path `app.ts`, use the router from `v1.ts` and put an `api/v1` prefix on all the paths.
-  Bazaglia defines an `HTTPRouter` class
   -  That class has a `get()` method that returns a new (`koa`) router with all the routes in one place.
   -  He also has a single `HTTPController` that has all his controllers in one place.

So, keep the routes and controllers in the module or centralize them?

-  Let's keep them in the module because modular makes reasoning simpler (most of the time).
-  We add routes by calling `fastify.get()` or whatever or `fastify.route(opts)` for each route.
   -  So, write functions that take a `FastifyInstance` and add routes to it.

Stemmler also has an `index.ts` in each use case directory that creates and exports the use case and controller. His routes import the controllers from the `index.ts` files and bind routes to them. He creates his use cases with the repo implementation.

How can I choose to use a test repo whose behavior I control in the test but use a real repo when not testing?

-  Could I use an environment variable to select the repo in one of the `index.ts` files? But how would it know the behavior the test wants?
-  But if the test repo is an implementation, could I mock it and override it? Possibly with more traditional jest syntax. (Then I could pick the implementation I want.)

For now, let's make the test repo an implementation in `backup-request/adapters/impl` and ignore the issue of picking it for testing.

-  `if process.env.NODE_ENV === 'test'` then jest is running the code

[] Add `backup-request/adapter/impl/BackupRequestRepo-test.ts`

-  Use code from the factory in `test-utils`
   [] Add `backup-request/use-cases/create-backup-request/index.ts`
-  use the test repo with an empty options list to instantiate the use case
   [] Test by overriding the repo methods.

Yeah. That won't work because I can't get the repo in the use case. From jest docs:

> Modules that are mocked with `jest.mock` are mocked only for the file that calls `jest.mock`. Another file that imports the module will get the original implementation even if it runs after the test file that mocks the module.

So, this becomes a true integration test with a live database because the use case needs a reference to the repo it uses as a constructor parameter. We need the use case to create the controller and the controller to create the route and the route to create the `FastifyInstance`. So all that becomes setup in the test, which means I'm not testing the setup code the application will use.

Either I set up a repo with known test data (I could do that with an in memory test repo, Bazagila has a simple example) or I can't test controllers.

I may be using a hammer to drive a screw here.

Notes to keep for now, but skip to "Rethink controller testing" section.

[] Add `backup-request/infrastructure/http/routes/fastifyRoutes.ts`

-  It should add a route for the controller.
   [] Add `app.ts` in `src` based on `zz-learn-fastify/index.ts`
-  `server.ts` can wait until we're ready to test the server

[] Create route for `POST backup-request` to call controller

-  Look at how Stemmler is managing routes
-  Look at [`fastify.route()`](https://www.fastify.io/docs/latest/Reference/Routes/#full-declaration)
   [] Use `fastify.inject()` to write test

[] Watch it fail
[] Write code to test for invalid `apiVersion` and return error
[] Confirm test passes
[] Write test for 500; watch it fail
[] Code to pass test
[] Write test for request is good; watch it fail
[] Code to pass test

## Replace controller in `zz-learn-fastify`

## Rethinking controller testing

I need a repo before I can test controllers.

I need to decide how I want to build that repo--use an actual database, some kind of in-memory solution, etc.

Then I need to build the repo, test data, etc.

Then I want to initialize the test repo and write some tests to prove it works. Those tests will be use case tests, but will need to use specific ids for some actions to get the expected data.

Then I can come back to controllers.

Before I go too far down that road, I want to read a bit about end to end testing tools and see if they offer any advantages over this approach. That may also lead me to some different strategies for end to end testing.

[x] Research end to end testing options
[x] Decide how to proceed with e2e, what pieces are truly needed, etc.
[] Define the plan.
[] Make it so.

The goal of this testing is to ensure that the service works as it should. At a basic level, HTTP calls to the service get the expected response. I'm fairly confident the use cases and aggregates will work given use case unit tests, so this is more about testing the connection between the adapters and infrastructure and the adapters and use cases.

Before I can instantiate controllers to test, I need repos to instantiate the use cases required to instantiate the controllers. So I need to shift focus to repos. I'll limit the initial focus to the create backup request feature, which will serve as a working model for other cases.

Also, some use cases will require a `BackupJobServiceAdapter` instance. For now, I'll use a mock.

I could create a simple in-memory test repo and use it instead of the real repo, but I think I'd be better served to use some kind of database interface--probably a multi-option ORM that lets me test with local SQLite and switch to a production grade database with no code changes. I can create a test data init script and run it before a series of tests. Some tests will involve chaining use cases, but that should flow naturally.

## Next steps

I'm closing the 4.x line to switch to repos (5.x). I'll return to controllers in 6.x.

**COMMIT: 4.2.3 - ADD: controller pieces for Fastify**

**COMMIT: 4.2.4 - MOVE: controllers to adapter** because they're adapters

**COMMIT: 4.2.5 - RENAME: controller test so it won't run because it doesn't work yet**
